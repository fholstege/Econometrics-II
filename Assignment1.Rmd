---
title: "Econometrics II - Assignment 1"
author: Floris Holstege, Stanislav Avdeev
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# Packages required for subsequent analysis. P_load ensures these will be installed and loaded. 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, 
               stargazer, 
               sampleSelection,
               lmtest,
               AER,
               tidyverse)

# load dataset
dfEarnings <- read.csv("Data/logEarnings.csv")

# set seed to reproduce analysis
set.seed(123)

```

# Exercise 1

```{r include=FALSE, eval=FALSE, echo=FALSE, results='hide'}

## Part A: Create a simple model with wages as dependent, schooling, age and age squared as independent
model1 = lm(logWage ~ schooling + age + age2, data = dfEarnings)
summary(model1)
stargazer(model1)



```

## A 

The only statistically significant variable (5\% threshold) is the measure for schooling. On average, an increase of one year of schooling leads to an 0.216 in the logged value of wages. 

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & Log of Wage \\ 
\hline \\[-1.8ex] 
 Schooling & 0.216$^{***}$ \\ 
  & (0.032) \\ 
  & \\ 
 Age & $-$0.342 \\ 
  & (0.521) \\ 
  & \\ 
 Age$^2$ & $-$0.011 \\ 
  & (0.008) \\ 
  & \\ 
 Intercept & 26.409$^{***}$ \\ 
  & (8.057) \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 416 \\ 
R$^{2}$ & 0.815 \\ 
Adjusted R$^{2}$ & 0.813 \\ 
Residual Std. Error & 1.499 (df = 412) \\ 
F Statistic & 604.261$^{***}$ (df = 3; 412) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

## B
The problem is that there is selection on unobservables and observables. We have a selected sample, excluding the unemployed. This means we have no info on their potential earnings, if they were employed. We cannot just extrapolate our findings in the selected sample to the non-employed, since the selection influences both unobservable variables (for example; the unemployed might have less motivation) and observable variables (for instance; the effect of years of schooling on earnings might be less strong for people who have not worked for some years).  

We model this selection bias in two steps. First, we indicate if the dependent variable is observed as follows:

\begin{align*}
I^*_i = Z'_i\gamma + V_i
\end{align*}

$I_i$ takes value 1 if $I^*_i > 0$, and 0 if $I^*_i \leq 0$. Second, we define our latent variable $Y^*_i$. 

\begin{align*}
Y^*_i = X'_i\beta + U_i
\end{align*}

We use these two definitions to define our observed dependent variable, $Y_i$.

\begin{align*}
Y_i =  \begin{cases}  Y^*_i  & \text{for } I_i = 1 \\
                      Missing & \text{for } I_i = 0 \end{cases}
\end{align*}

If we try to estimate $Y_i$ with OLS, it will be consistent under one of two conditions. First, if $U_i$ and $V_i$ are independent. The intuition here is that in this case, there isis random sampling. But this is not the case here, since the observations are removed from the selected sample based on a criterion (unemployment). Second, if $X_i$ and $Z_i$ are uncorrelated. The intuition here is that when this holds, the variables that determine if one falls outside of the selected sample ($Z_i$) are unrelated to the the independent variables used in the selected sample ($X_i$), and thus the zero mean condition ($E(U_i | X_i) = 0$) still holds. If neither of these two conditions hold, the OLS is inconsistent in this context. 

```{r include=FALSE, eval=FALSE, echo=FALSE, results='hide'}


# create indicator variable for unemployed
dfEarnings$unemployed = ifelse(is.na(dfEarnings$logWage),0,1)


# check correlation matrix with logged wages
cor(na.omit(dfEarnings) %>% select(-unemployed))

# check correlation matrix with unemployment (Indicator variable)
cor(dfEarnings %>% select(-logWage))



```

## C
The variable for the exclusion restriction should fulfill two conditions. First, the variable should have explanatory power when determining $I_i$. In this case, that means the variable should realistically influence the likelihood someone is unemployed. Second, the variable should be unrelated to the dependent variable $Y_i$. This means the variable should be unrelated to earnings. From the variables available, our best candidate appears to be the dummy variable of married (1 if married, 0 if not). Regarding the first condition; When someone is married, this affect their willingness to continue working, since they share income with their partner. Regarding the second condition; if one assumes that wages are reflective of someones productivity, the fact that someone is married, ceterus paribus, should not decrease one's productivity. However, there are some reasons to believe marriage still impacts wages - for one, married couples are more likely to have a baby, which likely affects ones earnings. But given the available variables, this appears the one that comes closest to fulfilling both criteria. Looking at the correlations, these confirm our intuitions; the correlation between marriage and unemployment is 0.17, but only 0.02 with logged wages. 


## D & E
```{r include=FALSE, eval=FALSE, echo=FALSE, results='hide'}

## Part D

### I first do it manually, and then with a package to compare


heckman <- function(formula_selection, formula_outcome, df){
  
  
  # get the independent variables for selection model
  dfX_selection <- model.matrix(formula_selection, df)

  # step 1 of heckman: use probit to estimate gamma
  heckman_step1 = glm(formula_selection, data = df, family = binomial(link="probit"))

  # use gamma to reconstruct millsratio
  Zgamma = dfX_selection %*% coef(heckman_step1)
  pdfNorm_Zgamma = dnorm(Zgamma, 0,1)
  cdfNorm_zgamma = pnorm(Zgamma, 0,1)
  invMillRatio= pdfNorm_Zgamma/cdfNorm_zgamma

  # define formula and dataframe for second step
  formula_step2 = update(formula_outcome, ~ . + invMillRatio)
  df_step2 = cbind(df, invMillRatio = invMillRatio)

  # step 2 of heckman: add millsratio to regular OLS with selected variables
  heckman_step2 = lm(formula_step2, data=df_step2)

  return(heckman_step2)

  
}

Result_Heckman_NoExclusion = heckman(unemployed ~ schooling + age + age2, logWage ~ schooling + age + age2, df=dfEarnings)

Result_Heckman_Exclusion = heckman(unemployed ~ schooling + age + age2 + married, logWage ~ schooling + age + age2, df=dfEarnings)


# using sample selection package for 2-step heckman
heckman_package= heckit(selection = unemployed ~ schooling + age + age2 + married,
                       outcome = logWage ~ schooling + age + age2, 
                       data = dfEarnings,
                       method="2step")
heckman_package

# our estimate is equal to that of the pacakge
RhoSigma_est_package =  heckman_package$invMillsRatio



## Part E

# using sample selection package for ML estimation
heckit(selection = unemployed ~ schooling + age + age2 + married,
       outcome = logWage ~ schooling + age + age2, 
       data = dfEarnings,
       method="ML")


```

## Exercise 2

```{r include=FALSE, eval=FALSE, echo=FALSE, results='hide'}


# original model
modelSchooling = lm(logWage ~ schooling, data = dfEarnings)
summary(modelSchooling)

#re-estimate models with the subsidy instrument
modelSchooling_subsidyIV <- ivreg(logWage ~ schooling | subsidy, data = dfEarnings)
summary(modelSchooling_subsidyIV, diagnostics=TRUE)


#re-estimate models with the distance instrument
modelSchooling_distanceIV <- ivreg(logWage ~ schooling | distance, data = dfEarnings)
summary(modelSchooling_distanceIV, diagnostics=TRUE)


#re-estimate models with the subsidy and distance instrument
modelSchooling_bothIV <- ivreg(logWage ~ schooling | distance + subsidy, data = dfEarnings)
summary(modelSchooling_bothIV, diagnostics=TRUE)

# prefer OLS over IV when not endogenous variables (since most efficient)


```
