slope_zerobeta = (D*sigma_p)/(C*(mu_p-mu_gmv))
df5 = data.frame(mu_zero_beta, 0)
names(df5) = c("average_returns", "standard_deviation")
## Plotting the tangent line
plot = ggplot(data = df2, aes(x = standard_deviation, y = average_returns))+
geom_path(data = df1[order(mu_grid),], aes(x = min_sigma, y = mu_grid), linetype = "longdash", colour = "red") +
geom_point() +
geom_point(data=df3, colour="red") +
geom_point(data=df4, colour = "blue") +
geom_text(data=df3, label="DJIA", vjust=1.5) +
geom_text(data=df4, label=TeX("$(\\sigma_p, \\mu_p)$"), size = 5, vjust = -1) +
geom_text(data=df5, label=TeX("$\\mu_{zp}$"), size = 5, vjust = -.5) +
geom_abline(intercept=mu_zero_beta, slope=slope_zerobeta, colour="blue") +
labs(title = "Mean-variance frontier for DJIA constituent stocks", x = "Variance", y = "Mean", subtitle = "Daily returns from March to December, 2019.") +
theme_bw()
plot
library(tidyquant) # download Yahoo finance data
install.packages("tidyquant")
library(tidyquant) # download Yahoo finance data
getSymbols("AAPL", from = '2017-01-01',
to = "2018-03-01",warnings = FALSE,
auto.assign = TRUE)
View(AAPL)
getSymbols("AAPL", from = '2019-12-31',
to = "2020-12-31",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2020-01-01',
to = "2020-12-31",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2020-01-01',
to = "2021-01-01",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2019-12-31',
to = "2021-01-01",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2019-12-31',
to = "2021-01-01",warnings = FALSE,
auto.assign = TRUE)
View(AAPL)
getSymbols("AAPL", from = '2019-12-31',
to = "2020-12-31",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2019-12-31',
to = "2021-01-01",warnings = FALSE,
auto.assign = TRUE)
getSymbols("AAPL", from = '2020-01-01',
to = "2021-01-01",warnings = FALSE,
auto.assign = TRUE)
chart_Series(AAPL)
tickers = c("GS", "MCD", "DOW", "CAT")
getSymbols(tickers, from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
chart_Series(AAPL)
tickers = c("GS", "MCD", "DOW", "CAT")
getSymbols(tickers, from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
tickers = c("GS", "MCD", "DOW", "CAT", MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
tickers = c("GS", "MCD", "DOW", "CAT", "MRK", "CVX", "VZ", "MSFT", "AMGN", "CSCO", "BA", "PG", "JPM", "WBA",
"DIS", "KO", "MMM", "AXP", "WMT", "JNJ", "HON", "V", "NKE", "AAPL", "CRM", "HD", "TRV", "UNH", "INTC", "IBM")
getSymbols(tickers, from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
prices <- merge(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
View(prices)
plot = autoplot(as.ts(returns), main = "Dow Jones Industrial Average daily stocks returns\n Mar/19 to Dec/19", xlab = "Time", ylab = "Return") +
theme_bw()
tickers = c("GS", "MCD", "DOW", "CAT", "MRK", "CVX", "VZ", "MSFT", "AMGN", "CSCO", "BA", "PG", "JPM", "WBA",
"DIS", "KO", "MMM", "AXP", "WMT", "JNJ", "HON", "V", "NKE", "AAPL", "CRM", "HD", "TRV", "UNH", "INTC", "IBM")
getSymbols(tickers, from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
prices <- merge(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
rm(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
getSymbols("DJI", from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
View(DJI)
View(prices)
skim(proces)
library(rio)
library(skim)
library(skimr)
skim(prices)
library(ggplot2, quietly = TRUE)
library(quantmod, quietly = T)
library(latex2exp, quietly = T)
library(PerformanceAnalytics, quietly = T)
library(ggfortify, quietly = T)
library(matrixcalc, quietly = T)
library(Matrix, quietly = T)
library(pracma, quietly = T)
# Questions 2 and 3
## Downloading and transforming data
### Information from the returns extracted from: https://finance.yahoo.com/quote/%5EDJI/components?ltr=1.
### Obs: Depending on the packages installed in your R version, the autoplot function will generate a different graph from what I pasted in the assigment. I tried to come up with something to fix it but it was taking too long.
### Obs2: Even though I downloaded data from almost two years, one of the stocks (DOW) has missing data in March, 2019, therefore the whole data set is cutted to the last complete set of observations. I was not sure if doing imputation for the missing data was going to help.
symbols <- c("UTX","MCD","PG","GS","WMT", "JPM", "DIS", "AXP", "V", "TRV", "PFE",
"BA", "MRK", "HD", "XOM", "JNJ", "MMM", "AAPL", "UNH", "CAT", "CVX",
"VZ", "CSCO","WBA", "IBM", "INTC", "NKE", "MSFT", "KO", "DOW", "DJIA")
getSymbols(symbols, src = 'yahoo', from = "2018-01-01", to="2019-12-27",
auto.assign = TRUE, warnings = FALSE)
prices <- merge(UTX, MCD,PG, GS, WMT, JPM, DIS, AXP, V, TRV, PFE,
BA, MRK, HD, XOM, JNJ, MMM, AAPL, UNH, CAT, CVX,
VZ, CSCO, WBA, IBM, INTC, NKE, MSFT, KO, DOW, DJIA)
prices <- prices[,grepl( "Close" , names(prices) )]
# There is something wrong with DOW, it has 304 outliers.
# Computing the returns
returns <- na.omit(Return.calculate(prices, method = "log"))*100
colnames(returns) <- c("UTX","MCD","PG","GS","WMT", "JPM", "DIS", "AXP", "V", "TRV", "PFE",
"BA", "MRK", "HD", "XOM", "JNJ", "MMM", "AAPL", "UNH", "CAT", "CVX",
"VZ", "CSCO","WBA", "IBM", "INTC", "NKE", "MSFT", "KO", "DOW", "DJIA")
summary(returns)
plot = autoplot(as.ts(returns), main = "Dow Jones Industrial Average daily stocks returns\n Mar/19 to Dec/19", xlab = "Time", ylab = "Return") +
theme_bw()
dates = index(returns)
plot
### The ingredients are the vector with the mean returns and the covariance matrix
mu_bar = apply(returns[,-ncol(returns)], 2, mean)
sigma  = var(returns[,-ncol(returns)])
## Being sure that is SPD
sigma = nearest_spd(sigma)
sigma_inverse = matrix.inverse(sigma)
## Computing the auxiliary quantities
A = rep(1,length(mu_bar)) %*% sigma_inverse %*% mu_bar
B = mu_bar %*% sigma_inverse %*% mu_bar
C = rep(1,length(mu_bar)) %*% sigma_inverse %*% rep(1,length(mu_bar))
D = (B*C)-A^2
## The minimum variance then can be find by making a grid of returns and will be given by
mu_grid = seq(-0.8, 0.8, 0.01)
min_sigma = sqrt(as.vector(rep(1/C, length(mu_grid))) + as.vector(rep(C/D, length(mu_grid))) * (mu_grid-as.vector(rep(A/C, length(mu_grid))))^2)
## Save results into a dataframe
df1 <- data.frame(mu_grid, min_sigma)
average_returns     = apply(returns, 2, mean)
standard_deviation  = apply(returns, 2, sd)
df2 <- data.frame(average_returns, standard_deviation)
row.names(df2) <- c("UTX","MCD","PG","GS","WMT", "JPM", "DIS", "AXP", "V", "TRV", "PFE",
"BA", "MRK", "HD", "XOM", "JNJ", "MMM", "AAPL", "UNH", "CAT", "CVX",
"VZ", "CSCO","WBA", "IBM", "INTC", "NKE", "MSFT", "KO", "DOW", "DJIA")
df3 <- df2["DJIA",]
plot = ggplot(data = df2, aes(x = standard_deviation, y = average_returns))+
geom_path(data = df1[order(mu_grid),], aes(x = min_sigma, y = mu_grid), linetype = "longdash", colour = "red") +
geom_point() +
geom_point(data=df3, colour="red") +
geom_text(data=df3, label="DJIA", vjust=1.5) +
labs(title = "Mean-variance frontier for DJIA constituent stocks", x = "Variance", y = "Mean", subtitle = "Daily returns from March to December, 2019.") +
theme_bw()
plot
View(df2)
View(returns)
z <- ts(matrix(100 + rnorm(200),100,2), start=c(1990,1), frequency=12)
z[z == 0] <- 1 # not to likely, but it can happen
View(z)
zyypc <- ytoypc(z)
zpc <- percentChange(z)
install.packages("percentChange")
library("percentChange")
rm(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
library(tidyquant) # download Yahoo finance data
library(skimr)
library(tidyverse)
tickers = c("GS", "MCD", "DOW", "CAT", "MRK", "CVX", "VZ", "MSFT", "AMGN", "CSCO", "BA", "PG", "JPM", "WBA",
"DIS", "KO", "MMM", "AXP", "WMT", "JNJ", "HON", "V", "NKE", "AAPL", "CRM", "HD", "TRV", "UNH", "INTC", "IBM")
getSymbols(tickers, from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
getSymbols("DJI", from = '2020-01-01',
to = "2021-01-01", warnings = FALSE,
auto.assign = TRUE)
prices <- merge(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
rm(GS, MCD, DOW, CAT, MRK, CVX, VZ, MSFT, AMGN, CSCO, BA, PG, JPM, WBA,
DIS, KO, MMM, AXP, WMT, JNJ, HON, V, NKE, AAPL, CRM, HD, TRV, UNH, INTC, IBM)
View(DJI)
View(prices)
View(DJI)
x <- prices[,grepl( "Close" , names(prices) )]
View(x)
x <- prices[, grepl("Adjusted", names(prices))]
View(x)
y <- Return.calculate(xts(x), method="discrete")
View(y)
y <- Return.calculate(xts(x), method="difference")
View(y)
y <- Return.calculate(xts(x), method="log")
View(y)
y <- Return.calculate(xts(x), method="discrete")
y <- Return.calculate(xts(x), method="discrete")**100
View(y)
x <- Return.calculate(xts(x), method="discrete")**100
rm(y)
x
x[1,1]
x[2,1]
6.222827e-194
x <- Return.calculate(xts(x), method="discrete")
x <- prices[, grepl("Adjusted", names(prices))]
x <- Return.calculate(xts(x), method="discrete")
x[2,1]
colnames(x) <- c("GS", "MCD", "DOW", "CAT", "MRK", "CVX", "VZ", "MSFT", "AMGN", "CSCO", "BA", "PG", "JPM", "WBA",
"DIS", "KO", "MMM", "AXP", "WMT", "JNJ", "HON", "V", "NKE", "AAPL", "CRM", "HD", "TRV", "UNH", "INTC", "IBM")
View(x)
df <- apply(x, mean())
y <- prices[, grepl("Adjusted", names(prices))]
y <- Return.calculate(xts(x), method="discrete")
y <- Return.calculate(xts(y), method="discrete")
df <- apply(x, mean(x))
df <- apply(x, function(x) mean)
View(y)
y <- prices[, grepl("Adjusted", names(prices))]
y <- Return.calculate(xts(y), method="discrete")
View(y)
df <- mean(y)
df <- mean(y[,1])
df <- mean(y[1,])
View(y)
df <- mean(y[2,])
y[2:30,]
y[-1,]
z <- y[-1,]
View(z)
y <- y[-1,]
df <- mean(y)
df <- prices[, grepl("Adjusted", names(prices))]
df <- Return.calculate(xts(df), method="discrete")
df <- df[-1,]
rm(x)
rm(y, z)
colnames(df) <- c("GS", "MCD", "DOW", "CAT", "MRK", "CVX", "VZ", "MSFT", "AMGN", "CSCO", "BA", "PG", "JPM", "WBA",
"DIS", "KO", "MMM", "AXP", "WMT", "JNJ", "HON", "V", "NKE", "AAPL", "CRM", "HD", "TRV", "UNH", "INTC", "IBM")
colMeans(df[sapply(df, is.numeric)])
means <- colMeans(df[sapply(df, is.numeric)])
library(rio)
library(stargazer)
# Problem 1: it's not consistent
# Problem 2
dfM <- import("Data/marriagemarket.dta")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
table(dfM$mortality)
library(rio)
library(stargazer)
# Problem 1: it's not consistent
# Problem 2
dfM <- import("Data/marriagemarket.dta")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
setwd("~/Documents/Econometrics-II")
# Problem 2
setwd("~/Documents/Econometrics-II")
dfM <- import("Data/marriagemarket.dta")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
table(dfM$mortality)
table(dfM$mortality_above)
View(dfM)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(na.omit(dfM$mortality) > median(na.omit(dfM$mortality)), 1, 0)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(is.na(dfM$mortality), NA, dfM$mortality > median(na.omit(dfM$mortality)), 1, 0))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(is.na(dfM$mortality), NA, dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(is.na(dfM$mortality), NA, ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0))
table(dfM$mortality_above)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(is.na(dfM$mortality), NA, 1)
table(dfM$mortality_above)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(is.na(dfM$mortality), NA, ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0))
table(dfM$mortality_above)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
table(dfM$mortality_above)
View(dfM)
table(dfM$mortality_above)
table(dfM$mortality_above, dfM$sr)
table(dfM$mortality_above, mean(dfM$sr))
dfM$post <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_above")))
dfM$post <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
# Problem 2
setwd("~/Documents/Econometrics-II")
dfM <- import("Data/marriagemarket.dta")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
table(dfM$groups)
39      +   48  +       39    +     48
dfM <- apply(dfM, 2, as.numeric)
dfM <- data.frame(apply(dfM, 2, as.numeric))
View(dfM)
# Problem 2
setwd("~/Documents/Econometrics-II")
dfM <- import("Data/marriagemarket.dta")
dfM <- data.frame(apply(dfM, 2, as.numeric))
View(dfM)
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
# Create a dummy for 4 groups: post and pre war + above and below median mortality
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
table(dfM$groups)
table(dfM$groups, dfM$mortality)
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
library(tidyverse)
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM)
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# Drop NA's
dfM <- drop_na(dfM$mortality)
# Drop NA's
dfM <- drop_na(dfM, "mortality")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(na.omit(dfM$mortality)), 1, 0)
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(dfM$mortality), 1, 0)
library(rio)
library(stargazer)
library(tidyverse)
# Problem 1: it's not consistent
# Problem 2
setwd("~/Documents/Econometrics-II")
dfM <- import("Data/marriagemarket.dta")
# Drop NA's
dfM <- drop_na(dfM, "mortality")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(dfM$mortality), 1, 0)
# Create a dummy for 4 groups: post and pre war + above and below median mortality
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
mean(dfM[dfM$groups == "Post_above",]$mortality)
DID <- mean(dfM[dfM$groups == "Post_above",]$mortality) - mean(dfM[dfM$groups == "Pre_above",]$mortality) - (mean(dfM[dfM$groups == "Post_below",]$mortality) - mean(dfM[dfM$groups == "Pre_below",]$mortality))
DID
mean(dfM[dfM$groups == "Post_above",]$mortality)
mean(dfM[dfM$groups == "Pre_above",]$mortality)
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
View(dfM)
table(dfM$groups)
DID
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
# Create a dummy for 4 groups: post and pre war + above and below median mortality
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
mean(dfM[dfM$groups == "Post_above",]$mortality)
mean(dfM[dfM$groups == "Pre_above",]$mortality
)
# Create a dummy for 4 groups: post and pre war + above and below median mortality
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
View(dfM)
#table(dfM$groups)
DID <- mean(dfM[dfM$groups == "Post_above",]$mortality) - mean(dfM[dfM$groups == "Pre_above",]$mortality) - (mean(dfM[dfM$groups == "Post_below",]$mortality) - mean(dfM[dfM$groups == "Pre_below",]$mortality))
DID
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post + mortality, dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
View(dfM)
dfM <- import("Data/marriagemarket.dta")
# Drop NA's
dfM <- drop_na(dfM, "mortality")
# I) Regress births on pre-war sex ratio
lm_pre <- lm(illeg ~ sr, dfM[dfM$post == 0,])
stargazer(lm_pre, type = "text",
keep.stat=c("n","adj.rsq"))
# II) Generate a dummy for whether the military mortality in a region is above thee median
dfM$mortality_above <- ifelse(dfM$mortality > median(dfM$mortality), 1, 0)
# Create a dummy for 4 groups: post and pre war + above and below median mortality
dfM$groups <- ifelse(dfM$post == 1 & dfM$mortality_above == 1, "Post_above", ifelse(dfM$post & dfM$mortality_above == 0, "Post_below", ifelse(dfM$mortality_above == 1, "Pre_above", "Pre_below")))
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
mean(dfM$mortality)
mean(dfM[dfM$post == 1,]$mortality)
mean(dfM[dfM$post == 0,]$mortality)
View(dfM)
mean(dfM[dfM$mortality_above == 0,]$mortality)
mean(dfM[dfM$mortality_above == 1,]$mortality)
mean(dfM[dfM$post == 1,]$mortality)
mean(dfM[dfM$post == 0,]$mortality)
dfM %>%
group_by(groups) %>%
summarise(Mortality = mean(mortality))
DID <- mean(dfM[dfM$groups == "Post_above",]$mortality) - mean(dfM[dfM$groups == "Pre_above",]$mortality) - (mean(dfM[dfM$groups == "Post_below",]$mortality) - mean(dfM[dfM$groups == "Pre_below",]$mortality))
DID
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
DID <- mean(dfM[dfM$groups == "Post_above",]$illeg) - mean(dfM[dfM$groups == "Pre_above",]$illeg) - (mean(dfM[dfM$groups == "Post_below",]$illeg) - mean(dfM[dfM$groups == "Pre_below",]$illeg))
DID
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
DID
mean(dfM[dfM$groups == "Post_above",]$illeg) - mean(dfM[dfM$groups == "Pre_above",]$illeg)
DID <- mean(dfM[dfM$groups == "Post_above",]$illeg) - mean(dfM[dfM$groups == "Pre_above",]$illeg) - (mean(dfM[dfM$groups == "Post_below",]$illeg) - mean(dfM[dfM$groups == "Pre_below",]$illeg))
DID
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post + mortality, dfM)
lm_DID
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
mean(dfM[dfM$groups == "Post_below",]$illeg) - mean(dfM[dfM$groups == "Pre_below",]$illeg)
mean(dfM[dfM$groups == "Post_above",]$illeg) - mean(dfM[dfM$groups == "Pre_above",]$illeg)
DID
1.068703 - 0.487792
lm_DID <- lm(illeg ~ post_mortality, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, type = "text",
keep.stat=c("n","adj.rsq"))
DID <- mean(dfM[dfM$groups == "Post_above",]$illeg) - mean(dfM[dfM$groups == "Pre_above",]$illeg) - (mean(dfM[dfM$groups == "Post_below",]$illeg) - mean(dfM[dfM$groups == "Pre_below",]$illeg))
DID
# III) Estimate DID regression
# Create a dummy for post*mortality
dfM$post_mortality <- dfM$post * dfM$mortality
lm_DID <- lm(illeg ~ post_mortality + post, dfM)
lm_DID_depc <- lm(illeg ~ post_mortality + post + as.factor(depc), dfM)
stargazer(lm_DID, lm_DID_depc, type = "text",
keep.stat=c("n","adj.rsq"))
