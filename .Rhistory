get_n_givenMDE <- function(Model_exp, sGroup, fAlpha, fPower, MDE, p, Sigma2=1){
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get variance of residuals
z <- (1/sqrt(p*(1-p)))*(1/(t_alpha - t_q))
n <- Sigma2/(z*MDE)^2
return(n)
}
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
n_low
get_n_givenMDE <- function(Model_exp, sGroup, fAlpha, fPower, MDE, p){
Sigma2 <- var(Model_exp$residuals)
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get variance of residuals
z <- (1/sqrt(p*(1-p)))*(1/(t_alpha - t_q))
n <- Sigma2/(z*MDE)^2
return(n)
}
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
n_low
get_n_givenMDE <- function(Model_exp, sGroup, fAlpha, fPower, MDE, p){
Sigma2 <- var(Model_exp$residuals)
print(Sigma2)
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get variance of residuals
z <- (1/sqrt(p*(1-p)))*(1/(t_alpha - t_q))
n <- Sigma2/(z*MDE)^2
return(n)
}
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
get_n_givenMDE <- function(Model_exp, sGroup, fAlpha, fPower, MDE, p, Sigma2 = 1){
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get variance of residuals
z <- (1/sqrt(p*(1-p)))*(1/(t_alpha - t_q))
n <- Sigma2/(z*MDE)^2
return(n)
}
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
n_low
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.1, 0.8, 0.1, 0.5)
n_low
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.5, 0.1, 0.5)
n_low
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
n_low
n_low <- get_n_givenMDE(LM_all_low, "bonus500", 0.05, 0.8, 0.1, 0.5)
n_low
all.equal(as.vector(test$v), as.vector(my$v))
library(PMA)
library(tidyverse)
library(gridExtra)
### FH: This makes the code not usable if I don't have these libraries - I would need to install them first. You can change this as follows:
### if (!require("pacman")) install.packages("pacman")
###  pacman::p_load(package1, package2, package_n)
#######################################################################
# DATA PREP
#######################################################################
# load in data
load("FIFA2017_NL.RData")
# tidy data
fifa$Position <- fct_recode(fifa$Position, Goalkeeper = "Gk",
Defender = "Def", Midfielder = "Mid",
Forward = "FW")
# drop name column
X <- fifa %>% select(!c("name", "club", "Position", "eur_value",
"eur_wage", "eur_release_clause"))
# bring into matrix form, exclude intercept
X <- model.matrix(~. -1, X)
# normalise data
X <- scale(X)
#######################################################################
# FUNCTIONS
#######################################################################
# soft thresholding function
soft_thresh <- function(x, lambda) {
sign(x) * (pmax(abs(x) - lambda, 0))
}
# soft thresholding function divided by L2 norm
soft_l2norm <- function(x, lambda) {
x <- soft_thresh(x = x, lambda = lambda)
x_l2 <- sqrt(sum(x^2))
if (abs(x_l2) > .Machine$double.eps^0.5) {
x <- x / x_l2
}
x
}
# binary search function to determine optimal lambda
binary_search <- function(x, c, maxit = 100) {
## Check if x already meets the condition, or whether c is zero
x_l1 <- sum(abs(x))
if (x_l1 <= c || c == 0) {
return(0)
}
## Initialize search boundaries and iteration counter
lo <- 0
hi <- max(abs(x))
i <- 0
## Iterate
while(i < maxit) {
## Increase iteration count
i <- i + 1
## Get mean of current bounds, and evaluate L1 norm there
m <- lo + (hi - lo)/2
m_l1 <- sum(abs(soft_l2norm(x, m)))
## Update either lower or upper threshold
if (m_l1 <= c) {
hi <- m
} else {
lo <- m
}
## Break if lo and hi have converged
if (abs(lo - hi) <= sqrt(.Machine$double.eps)) {
break
}
}
return(lo + (hi - lo)/2)
}
# penalised rank one SVD
penSVD <- function(X, c1, c2, imax = 100){
# initialise parameters
v <- svd(X, nu = 0, nv = 1)$v
i <- 0
cat("Finding penalised rank-1 SVD over", imax, "steps.\n")
while (i < imax) {
i <- i + 1
if (i %% 5 == 0){
cat("Iteration", i, "\n")
}
# compute X times v
Xv <- X %*% v
# binary search for smallest lambda1 s.t. l1norm of u <= c1
lambda1 <- binary_search(Xv, c1, maxit = 100)
# update u
u <- soft_l2norm(Xv, lambda1)
# compute X'u
Xu <- t(X)  %*% u
# binary search for smallest lambda2 s.t. l1norm of v <= c2
lambda2 <- binary_search(Xu, c2, maxit = 100)
# update v
v <- soft_l2norm(Xu, lambda2)
}
cat("Algorithm converged.\n")
return(list(u = u, v = v, sigma = t(u) %*% X %*% v))
}
# compare results
# unpenalised, so just SVD
test <- PMD(X, sumabsu = sqrt(nrow(X)), sumabsv = sqrt(ncol(X)), center = FALSE)
# drop name column
X <- fifa %>% select(!c("name", "club", "Position", "eur_value",
"eur_wage", "eur_release_clause"))
# tidy data
fifa$Position <- fct_recode(fifa$Position, Goalkeeper = "Gk",
Defender = "Def", Midfielder = "Mid",
Forward = "FW")
# load in data
load("FIFA2017_NL.RData")
getwd()
setwd("C:/Users/flori/OneDrive/Documents/Tinbergen/Courses/USML")
# load in data
load("Data/FIFA2017_NL.RData")
fifa$Position <- fct_recode(fifa$Position, Goalkeeper = "Gk",
Defender = "Def", Midfielder = "Mid",
Forward = "FW")
# drop name column
X <- fifa %>% select(!c("name", "club", "Position", "eur_value",
"eur_wage", "eur_release_clause"))
# bring into matrix form, exclude intercept
X <- model.matrix(~. -1, X)
# normalise data
X <- scale(X)
#######################################################################
# FUNCTIONS
#######################################################################
# soft thresholding function
soft_thresh <- function(x, lambda) {
sign(x) * (pmax(abs(x) - lambda, 0))
}
# soft thresholding function divided by L2 norm
soft_l2norm <- function(x, lambda) {
x <- soft_thresh(x = x, lambda = lambda)
x_l2 <- sqrt(sum(x^2))
if (abs(x_l2) > .Machine$double.eps^0.5) {
x <- x / x_l2
}
x
}
# binary search function to determine optimal lambda
binary_search <- function(x, c, maxit = 100) {
## Check if x already meets the condition, or whether c is zero
x_l1 <- sum(abs(x))
if (x_l1 <= c || c == 0) {
return(0)
}
## Initialize search boundaries and iteration counter
lo <- 0
hi <- max(abs(x))
i <- 0
## Iterate
while(i < maxit) {
## Increase iteration count
i <- i + 1
## Get mean of current bounds, and evaluate L1 norm there
m <- lo + (hi - lo)/2
m_l1 <- sum(abs(soft_l2norm(x, m)))
## Update either lower or upper threshold
if (m_l1 <= c) {
hi <- m
} else {
lo <- m
}
## Break if lo and hi have converged
if (abs(lo - hi) <= sqrt(.Machine$double.eps)) {
break
}
}
return(lo + (hi - lo)/2)
}
# penalised rank one SVD
penSVD <- function(X, c1, c2, imax = 100){
# initialise parameters
v <- svd(X, nu = 0, nv = 1)$v
i <- 0
cat("Finding penalised rank-1 SVD over", imax, "steps.\n")
while (i < imax) {
i <- i + 1
if (i %% 5 == 0){
cat("Iteration", i, "\n")
}
# compute X times v
Xv <- X %*% v
# binary search for smallest lambda1 s.t. l1norm of u <= c1
lambda1 <- binary_search(Xv, c1, maxit = 100)
# update u
u <- soft_l2norm(Xv, lambda1)
# compute X'u
Xu <- t(X)  %*% u
# binary search for smallest lambda2 s.t. l1norm of v <= c2
lambda2 <- binary_search(Xu, c2, maxit = 100)
# update v
v <- soft_l2norm(Xu, lambda2)
}
cat("Algorithm converged.\n")
return(list(u = u, v = v, sigma = t(u) %*% X %*% v))
}
# compare results
# unpenalised, so just SVD
test <- PMD(X, sumabsu = sqrt(nrow(X)), sumabsv = sqrt(ncol(X)), center = FALSE)
test$v
my <- penSVD(X, c1 = sqrt(nrow(X)), c2 = sqrt(ncol(X)))
my$v
all.equal(as.vector(test$v), as.vector(my$v))
# sparse function
sparserankonePCA <- function(X, c2, imax, verbose = TRUE){
# initialise parameters
v <- svd(X, nu = 0, nv = 1)$v
i <- 0
while (i < imax) {
i <- i + 1
if ((i %% 5 == 0) & (isTRUE(verbose))){
cat("Iteration", i, "\n")
}
# compute X times v
Xv <- X %*% v
# update u
u <- Xv / sqrt(sum(Xv^2))
# compute X'u
Xu <- t(X) %*% u
# binary search for smallest lambda2 s.t. l1norm of v <= c2
lambda2 <- binary_search(Xu, c2, maxit = 100)
# update v
v <- soft_l2norm(Xu, lambda2)
}
return(list(u = u, v = v, sigma = as.numeric(t(u) %*% X %*% v)))
}
# sparse PCA function
sparsePCA <- function(X, K, c2, imax){
# check that c2 is correctly specified
if (c2 < 1 | c2 > sqrt(ncol(X))){
stop("c2 not within feasible interval (1 <= c2 <= sqrt(p)")
}
# initialise parameters
R <- X
SIGMA <- matrix(NA, nrow = K, ncol = 1)
U <- matrix(NA, nrow = nrow(X), ncol = K)
V <- matrix(NA, nrow = ncol(X), ncol = K)
cat("Initialisation finished.\n")
for (k in 1:K) {
cat("Rank-1 PCA - Iteration ", k, "\n")
# get sparse rank one PCA
results <- sparserankonePCA(R, c2 = c2, imax = imax, verbose = FALSE)
# save rank one results
SIGMA[k,1] <- results$sigma
U[,k] <- results$u
V[,k] <- results$v
# update R matrix
R <- R - (as.numeric(results$sigma) * as.matrix(results$u) %*% t(as.matrix(results$v)))
}
return(list(u = U, v = V, sigma = SIGMA))
}
# compare penalised SVD results
test <- SPC(X, sumabsv = 3, K = 2, center = FALSE, trace = FALSE)
my <- sparsePCA(X, K = 2, c2 = 3, imax =1000)
test$u[1:10,]
my$u[1:10,]
test$v[1:10,]
my$v[1:10,]
all.equal(as.vector(test$v), as.vector(my$v))
all.equal(as.vector(abs(test$u)), as.vector(abs(my$u)))
# compare unpenalised results, equivalent to ordinary SVD
test <- SPC(X, sumabsv = sqrt(ncol(X)), K = ncol(X), center = FALSE, trace = FALSE)
my <- sparsePCA(X, K = ncol(X), c2 = sqrt(ncol(X)), imax =1000)
# check near equivalence
all.equal(as.vector(abs(test$u)), as.vector(abs(my$u)))
all.equal(as.vector(abs(test$v)), as.vector(abs(my$v)))
all.equal(as.vector(test$d), as.vector(my$sigma))
as.vector(abs(test$u))
as.vector(abs(my$u))
# plot using own function and scarce SVD
# do PCA with own function
results <- sparsePCA(X, K = 6, c2 = 4, imax = 1000)
# compute principal components
PC1 <- as.data.frame(X %*% results$v[,1])
PC2 <- as.data.frame(X %*% results$v[,2])
# generate dataframe for plotting
plotdf_own <- as.data.frame(cbind(fifa$Position, PC1, PC2))
names(plotdf_own) <- c("Position", "pc1", "pc2")
# construct plot
ownplot <- ggplot(aes(x = pc1, y = pc2, color = Position), data = plotdf_own) +
geom_point() + xlab("First Principal Component") +
ylab("Second Principal Component") + ggtitle("Own Implementation") + theme_bw()
ownplot
#######################################################################
# MAIN ANALYSIS AND RESULTS
#######################################################################
# first plot scree plot to determine number of factors to retain
fullpca <- prcomp(X, center = FALSE)
# check prop of variance explained
summary(fullpca)
# scree plot
pdf("screeplot.pdf")
scree <- plot(fullpca, type = "l", main = "")
dev.off()
# for 2 factors find the optimal c2
set.seed(1)
CVresults <- SPC.cv(X, sumabsvs = seq(1, sqrt(ncol(X)), length = 60),
nfolds = 10, center = FALSE)
c2 <- CVresults$bestsumabsv1se
# conduct sparse PCA
sparsepca <- SPC(X, sumabsv = 4.5, K = 2, center = FALSE)
# format factor loadings
fl <- sparsepca$v
rownames(fl) <- colnames(X)
colnames(fl) <- c("PC1", "PC2")
fl <- as.data.frame(fl)
# output first loadings
fl1 <- fl %>% arrange(desc(abs(PC1)))
fl1 <- fl1 %>% select(PC1)
xtable(fl1)
# output second loadings
fl2 <- fl %>% arrange(desc(abs(PC2)))
fl2 <- fl2 %>% select(PC2)
xtable(fl2)
# plots
# compute principal components
PC1 <- as.data.frame(X %*% sparsepca$v[,1])
PC2 <- as.data.frame(X %*% sparsepca$v[,2])
# generate dataframe for plotting
plotdf <- as.data.frame(cbind(fifa$Position, PC1, PC2))
names(plotdf) <- c("Position", "pc1", "pc2")
# construct plot
resultsplot <- ggplot(aes(x = pc1, y = pc2, color = Position), data = plotdf) +
geom_point() + xlab("First Principal Component") +
ylab("Second Principal Component") + theme_bw() + theme(legend.position = "top")
resultsplot
# sparse function
sparserankonePCA <- function(X, c2, imax, verbose = TRUE){
### When does it converge?
# initialise parameters
v <- svd(X, nu = 0, nv = 1)$v
i <- 0
while (i < imax) {
i <- i + 1
## tell number of iterations
if ((i %% 5 == 0) & (isTRUE(verbose))){
cat("Iteration", i, "\n")
}
# compute X times v
Xv <- X %*% v
# update u
u <- Xv / sqrt(sum(Xv^2))
# compute X'u
Xu <- t(X) %*% u
# binary search for smallest lambda2 s.t. l1norm of v <= c2
lambda2 <- binary_search(Xu, c2, maxit = 100)
# update v
v <- soft_l2norm(Xu, lambda2)
}
return(list(u = u, v = v, sigma = as.numeric(t(u) %*% X %*% v)))
}
my <- sparsePCA(X, K = 2, c2 = 3, imax =1000)
dfJudge <- data.frame( cases = c(0.7, 0.3, 0.4, 0.6), arrests = c(0.4, 0.6, 0.2, 0.5) )
rownames(dfJudge) <- c("Jones-Prison", "Jones-Other", "Smith-Prison", "Smith-Other")
dfJudge
Wald_est <- (dfJudge$cases[1,]- dfJudge$cases[3,])/(dfJudge$arrests[1,] - dfJudge$arrests[3,])
Wald_est <- (dfJudge$cases[1]- dfJudge$cases[3])/(dfJudge$arrests[1] - dfJudge$arrests[3])
wald_est
wald_est <- (dfJudge$cases[1]- dfJudge$cases[3])/(dfJudge$arrests[1] - dfJudge$arrests[3])
wald_est
dfJudge <- data.frame( cases = c(0.7, 0.3, 0.4, 0.6), arrests = c(0.4, 0.6, 0.2, 0.5) )
rownames(dfJudge) <- c("Jones-Prison", "Jones-Other", "Smith-Prison", "Smith-Other")
wald_est <- (dfJudge$cases[1]- dfJudge$cases[3])/(dfJudge$arrests[1] - dfJudge$arrests[3])
dfJudge <- data.frame( cases = c(0.7, 0.3, 0.4, 0.6), arrests = c(0.4, 0.6, 0.2, 0.5) )
rownames(dfJudge) <- c("Jones-Prison", "Jones-Other", "Smith-Prison", "Smith-Other")
wald_est <- (dfJudge$arrests[1]- dfJudge$arrests[3])/(dfJudge$cases[1] - dfJudge$cases[3])
wald_est
dfJudge$arrests[1]
dfJudge$arrests[3]
dfJudge$cases[1]
dfJudge$cases[3]
get_n_givenMDE <- function(MDE, fAlpha, fPower, p, Sigma2){
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get variance of residuals
z <- (1/sqrt(p*(1-p)))*(1/(t_alpha - t_q))
n <- Sigma2/(z*MDE)^2
return(n)
}
sigma2 <- p* (1- p)
MDE = 0.1
fAlpha = 0.05
fPower = 0.7
p = 0.5
sigma2 <- p* (1- p)
get_n_givenMDE(MDE, fAlpha, fPower, p, Sigma2)
get_n_givenMDE(MDE, fAlpha, fPower, p, sigma2)
get_n_givenMDE <- function(MDE, fAlpha, fPower, p, Sigma2){
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get the MDE
size <- (((t_alpha - t_q)/MDE)^2) * sigma2/(p*(1-p))
size <- round(size, 0)
return(size)
}
get_n_givenMDE(MDE, fAlpha, fPower, p, sigma2)
, fPower, p, sigma2)
perc_nonComply <- 0.2
size = get_size_givenMDE(MDE, fAlpha, fPower, p, sigma2)
get_size_givenMDE <- function(MDE, fAlpha, fPower, p, Sigma2){
# get t values
t_alpha <- qnorm(1-fAlpha/2, 0,Sigma2)
t_q <-qnorm(1-fPower, 0,Sigma2)
# get the MDE
size <- (((t_alpha - t_q)/MDE)^2) * sigma2/(p*(1-p))
size <- round(size, 0)
return(size)
}
MDE = 0.1
fAlpha = 0.05
fPower = 0.7
p = 0.5
sigma2 <- p* (1- p)
size = get_size_givenMDE(MDE, fAlpha, fPower, p, sigma2)
perc_nonComply <- 0.2
new_size = (1/(1-perc_nonComply))*size
new_size
new_size = (1/(1-perc_nonComply)^2)*size
new_size
getwd()
load("Data/FluData.dta")
read.table("Data/FluData.dta")
read.dta("Data/FluData.dta")
library(foreign)
read.dta("Data/FluData.dta")
install.packages("readstata13")
library(readstata13)
read.dta13("Data/FluData.dta")
dfFlu <- read.dta13("Data/FluData.dta")
dfFlu$TreatGroup == 1
dfFlu_treatment <- dfFlu[dfFlu$TreatGroup == 1,]
dfFlu_control <- dfFlu[dfFlu$TreatGroup == 0,]
dfFlu_treatment$Flu
var(dfFlu_treatment$Flu)
sum(dfFlu_treatment$Flu)
sum(dfFlu_treatment$Flu)/nrow(dfFlu_treatment)
p <- sum(dfFlu_treatment$Flu)/nrow(dfFlu_treatment)
p(1-p)
p <- sum(dfFlu_treatment$Flu)/nrow(dfFlu_treatment)
p(1-p)
p*(1-p)
get_size_givenMDE(0.05, fAlpha, fPower, p, sigma2)
p_flu <- sum(dfFlu_treatment$Flu)/nrow(dfFlu_treatment)
sigma2_flu <- p*(1-p)
get_size_givenMDE(0.05, fAlpha, fPower, p_flu, sigma2_flu)
dfFlu_actualTreatment <- dfFlu_treament[dfFlu_treatment$Treatment == 1,]
dfFlu_actualTreatment <- dfFlu_treatment[dfFlu_treatment$Treatment == 1,]
nrow(dfFlu_actualTreatment)/nrow(dfFlu_treatment)
size_flu <- get_size_givenMDE(0.05, fAlpha, fPower, p_flu, sigma2_flu)
dfFlu_actualTreatment <- dfFlu_treament[dfFlu_treatment$Treatment == 1,]
perc_comply_flu <- nrow(dfFlu_actualTreatment)/nrow(dfFlu_treatment)
new_size_flu = (1/(perc_comply_flu)^2)*size_flu
dfFlu_actualTreatment <- dfFlu_treatment[dfFlu_treatment$Treatment == 1,]
new_size_flu = (1/(perc_comply_flu)^2)*size_flu
new_size_flu
